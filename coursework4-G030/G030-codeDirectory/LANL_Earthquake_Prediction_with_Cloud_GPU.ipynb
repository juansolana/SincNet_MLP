{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LANL Earthquake Prediction with Cloud GPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juansolana/SincNet_MLP/blob/master/LANL_Earthquake_Prediction_with_Cloud_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FvTvVlI8NwUJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LANL Earthquake Prediction with Cloud GPU\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\" >\n",
        " <td>\n",
        "    <a target=\"_blank\" href=\"https://www.kaggle.com/c/LANL-Earthquake-Prediction\"><img src=\"https://www.kaggle.com/static/images/site-logo.png\" width='82' />View competition</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/icewing1996/SincNet_MLP\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "metadata": {
        "id": "IURuWVGVNMn_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Firstly**, log in to Google so that you can access the data on Google Cloud"
      ]
    },
    {
      "metadata": {
        "id": "I_fPzsyaerTq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "import math\n",
        "import os\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yls9qsaG4TwW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Secondly**, download code from GitHub"
      ]
    },
    {
      "metadata": {
        "id": "4Y-1h2UFGPe8",
        "colab_type": "code",
        "outputId": "56cba18a-21af-440d-ccbe-3bcefc0a522b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf SincNet_MLP\n",
        "!git clone https://github.com/juansolana/SincNet_MLP\n",
        "os.chdir('SincNet_MLP')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SincNet_MLP'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 397 (delta 16), reused 0 (delta 0), pack-reused 368\u001b[K\n",
            "Receiving objects: 100% (397/397), 185.70 KiB | 5.80 MiB/s, done.\n",
            "Resolving deltas: 100% (255/255), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZBNWgDNXNqnu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Thirdly**, specify dataset to use and download them from Google Cloud:\n",
        "\n",
        "\n",
        "*   **Raw audio** with each 150,000 datapoint segment downsampled to N datapoints. \n",
        "   * **4000**: N = 4000, using last point as target\n",
        "   * **4000mid**: N = 4000, using mid point as target\n",
        "   * **40000**: N = 40000, using last point as target\n",
        "   * **40000_mid**: N = 40000, using mid point as target\n",
        "   \n",
        "* **Handcrafted features** with each 150,000 datapoint segment split into 150 mini-segments (statistics calculated over each 1,000 points).\n",
        "   * **features_last**: mean, min, max, std, 4 quantiles, using last point as target\n",
        "   * **features_mid**: same as above, using mid point as target\n",
        "   * **more_feautres_mid**: in addition to above, kurtosis, variance, skew, median, mad, abs_mean, abs_std, using mid point as target\n",
        "   * **sliding_features_mid**: same as **features_mid**, except using sliding window 3750 datapoints at a time on train and dev sets (40x data augmentation)*** (can NOT directly compare to other datasets)***, train+dev shape (167733, 150, 8)\n"
      ]
    },
    {
      "metadata": {
        "id": "T3UfdE10GS1F",
        "colab_type": "code",
        "outputId": "7f16a974-9167-40b4-f2e7-0c5616ae8149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "cell_type": "code",
      "source": [
        "DATASET = \"more_feautres_mid\" #@param ['4000', '4000mid', '40000', '40000_mid', 'features_last', 'features_mid', 'more_feautres_mid', 'sliding_features_mid', 'sliding_more_features_mid', 'sliding_more_features_last']\n",
        "#DDATASET = \"features_mid\"\n",
        "!gsutil cp gs://edinquake/prepared_data/$DATASET/train_signals prepared_data/train_signals\n",
        "!gsutil cp gs://edinquake/prepared_data/$DATASET/train_labels prepared_data/train_labels\n",
        "!gsutil cp gs://edinquake/prepared_data/$DATASET/dev_signals prepared_data/dev_signals\n",
        "!gsutil cp gs://edinquake/prepared_data/$DATASET/dev_labels prepared_data/dev_labels\n",
        "!gsutil cp gs://edinquake/prepared_data/$DATASET/test_signals prepared_data/test_signals\n",
        "!gsutil cp gs://edinquake/prepared_data/$DATASET/test_labels prepared_data//test_labels"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://edinquake/prepared_data/more_feautres_mid/train_signals...\n",
            "\\\n",
            "Operation completed over 1 objects/64.8 MiB.                                     \n",
            "Copying gs://edinquake/prepared_data/more_feautres_mid/train_labels...\n",
            "/ [1 files][ 29.6 KiB/ 29.6 KiB]                                                \n",
            "Operation completed over 1 objects/29.6 KiB.                                     \n",
            "Copying gs://edinquake/prepared_data/more_feautres_mid/dev_signals...\n",
            "/ [1 files][  7.2 MiB/  7.2 MiB]                                                \n",
            "Operation completed over 1 objects/7.2 MiB.                                      \n",
            "Copying gs://edinquake/prepared_data/more_feautres_mid/dev_labels...\n",
            "/ [1 files][  3.4 KiB/  3.4 KiB]                                                \n",
            "Operation completed over 1 objects/3.4 KiB.                                      \n",
            "Copying gs://edinquake/prepared_data/more_feautres_mid/test_signals...\n",
            "- [1 files][ 45.0 MiB/ 45.0 MiB]                                                \n",
            "Operation completed over 1 objects/45.0 MiB.                                     \n",
            "Copying gs://edinquake/prepared_data/more_feautres_mid/test_labels...\n",
            "/ [1 files][ 20.7 KiB/ 20.7 KiB]                                                \n",
            "Operation completed over 1 objects/20.7 KiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YQMnSCcOU7Oy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Fun times!**\n",
        "\n",
        "\n",
        "1.   Pick a model:\n",
        "   *   **raw** models use raw audio data; **features** models use handcrafted features\n",
        "   *  It only makes sense for [SincNet](https://arxiv.org/abs/1808.00158) to use raw audio data\n",
        "   *  [Transformer](https://arxiv.org/abs/1706.03762) runs out of memory on **raw** data (makes sense since its memory cost is quadratic the length of the input)\n",
        "\n",
        "2.   Specify hyperparameters (change only relevant models but make sure to*** run all cells***)\n",
        "3.   Profit\n",
        "\n",
        "**WLEN** must equal number of input features:\n",
        "   *  8 for **fetures_mid**, **features_last**, and **sliding_features_mid**\n",
        "   * 15 for **more_feautres_mid**\n",
        "   * 4000 for **4000** and **4000mid**\n",
        "   * 40000 for **40000** and **40000_mid**\n",
        "\n",
        "**BATCH_NORM** and **LAY_NORM** ***cannot*** be applied in the same layer at the same time\n",
        "\n",
        "**Activation functions** can be one of **softplus, relu, tanh, sigmoid, leaky_relu, elu, softmax, linear**"
      ]
    },
    {
      "metadata": {
        "id": "C3qa1yU_xVDf",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MODEL = \"Transformer_features\" #@param [\"Transformer_features\", \"LSTM_raw\", \"LSTM_features\", \"CNN_raw\", \"CNN_features\", \"SincNet_raw\"]\n",
        "WLEN=\"15\" #@param [8, 15, 4000, 40000]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZCRpYZ4xIHL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Transformer** hyperparameters:\n",
        "*   **TRANSFORMER_EMBED_DIM**:\n",
        "   *  input dimension to transformer\n",
        "   *  must equal last dimension of **DNN_before** if using **DNN_before** \n",
        "   *  must equal number of input features otherwise\n",
        "      *  8 for **fetures_mid**, **features_last**, and **sliding_features_mid**\n",
        "      * 15 for **more_feautres_mid**\n",
        "*   **TRANSFORMER_HIDDEN_SIZE**:\n",
        "   *  must equal **TRANSFORMER_EMBED_DIM**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "353oIQVYvgUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# [transformer]\n",
        "TRANSFORMER_EMBED_DIM = 256 #@param {type:\"number\"}\n",
        "TRANSFORMER_MAX_POSITIONS = 1024\n",
        "POSITION_EMBEDDING_TYPE = 'learned' #@param ['learned', 'timing']\n",
        "TRANSFORMER_NUM_LAYERS = 4 #@param {type:\"number\"}\n",
        "TRANSFORMER_NUM_HEADS = 16 #@param {type:\"number\"}\n",
        "TRANSFORMER_FILTER_SIZE = 256 #@param {type:\"number\"}\n",
        "TRANSFORMER_HIDDEN_SIZE = 256 #@param {type:\"number\"}\n",
        "TRANSFORMER_DROPOUT = 0.1 #@param {type:\"number\"}\n",
        "TRANSFORMER_ATTENTION_DROPOUT = 0.1 #@param {type:\"number\"}\n",
        "TRANSFORMER_RELU_DROPOUT = 0.1 #@param {type:\"number\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ybn9RaX7xhxh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**LSTM** hyperparameters:\n",
        "\n",
        "*  **LSTM_EMBED_DIM**:\n",
        "   *  input dimension to transformer\n",
        "   *  must equal last dimension of **DNN_before** if using **DNN_before** \n",
        "   *  must equal number of input features otherwise\n",
        "      *  8 for **fetures_mid**, **features_last**, and **sliding_features_mid**\n",
        "      * 15 for **more_feautres_mid**\n"
      ]
    },
    {
      "metadata": {
        "id": "0UCvyNmLxm35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# [lstm]\n",
        "LSTM_EMBED_DIM=256 #@param {type:\"number\"}\n",
        "LSTM_HIDDEN_SIZE=256 #@param {type:\"number\"}\n",
        "LSTM_NUM_LAYERS=4 #@param {type:\"number\"}\n",
        "LSTM_BIDIRECTIONAL='True' #@param ['True', 'False']\n",
        "LSTM_DROPOUT_IN=0.25 #@param {type:\"number\"}\n",
        "LSTM_DROPOUT_OUT=0.25 #@param {type:\"number\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6JmrNpn_xoeY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**SincNet/ CNN** hyperparameters (see **DNN_before** for how to fill)"
      ]
    },
    {
      "metadata": {
        "id": "ZPIRp9Y_xn_k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# [cnn]\n",
        "CNN_N_FILT='80,60,60' #@param {type:\"string\"}\n",
        "CNN_LEN_FILT='25,5,5' #@param {type:\"string\"}\n",
        "CNN_MAX_POOL_LEN='3,3,3' #@param {type:\"string\"}\n",
        "CNN_USE_LAYNORM_INP='True' #@param ['True', 'False']\n",
        "CNN_USE_BATCHNORM_INP='False' #@param ['True', 'False']\n",
        "CNN_USE_LAYNORM='False,False,False' #@param {type:\"string\"}\n",
        "CNN_USE_BATCHNORM='True,True,True' #@param {type:\"string\"}\n",
        "CNN_ACT='leaky_relu,leaky_relu,leaky_relu' #@param {type:\"string\"}\n",
        "CNN_DROP='0.0,0.0,0.0' #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JRnyjkaWkyyv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DNN_before** hyperparameters: \n",
        "*   Optionally have an MLP before feeding input to CNN/LSTM/Transformer\n",
        "    *   **FC1_LAY_USE**: whether to use **DNN_before**\n",
        "    *   **FC1_LAY**: dimension of each layer, **e.g.** \"256,256,1028\" ***(note NO whitespace)***\n",
        "    *   **FC1_DROP**: dropoput rate of each layer, **e.g.** \"0.0,0.0\"\n",
        "    *   **FC1_USE_LAYNORM_INP**: whether to use layer normalization at input\n",
        "    *   **FC1_USE_BATCHNORM_INP**: whether to use batch normalization at input\n",
        "    *   **FC1_USE_BATCHNORM**: whether batchnorm at each layer,** e.g.** \"True,True,True\"\n",
        "    *   **FC1_USE_LAYNORM**: whether laynorm at each layer, **e.g.** \"False,False,False\"\n",
        "    *   **FC1_ACT**: activation function of each layer,** e.g.** \"leaky_relu,leaky_relu,leaky_relu\"\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "E8_ZtHhFkyEQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# [dnn_before]\n",
        "FC1_LAY_USE='True' #@param ['True', 'False']\n",
        "FC1_LAY='256' #@param {type: \"string\"}\n",
        "FC1_DROP='0.0' #@param {type: \"string\"}\n",
        "FC1_USE_LAYNORM_INP='False' #@param ['True', 'False']\n",
        "FC1_USE_BATCHNORM_INP='False' #@param ['True', 'False']\n",
        "FC1_USE_BATCHNORM='False' #@param {type: \"string\"}\n",
        "FC1_USE_LAYNORM='False' #@param {type: \"string\"}\n",
        "FC1_ACT='relu' #@param {type: \"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WX9xzRGD42zH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DNN_after** hyperparameters (everything same as **DNN_before**):\n",
        "*   The MLP after CNN/LSTM/Transformer"
      ]
    },
    {
      "metadata": {
        "id": "jDkZcO9ythLp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# [dnn_after]\n",
        "FC2_LAY='10,10' #@param {type: \"string\"}\n",
        "FC2_DROP='0.0,0.0' #@param {type: \"string\"}\n",
        "FC2_USE_LAYNORM_INP='False' #@param ['True', 'False']\n",
        "FC2_USE_BATCHNORM_INP='False' #@param ['True', 'False']\n",
        "FC2_USE_BATCHNORM='False,False' #@param {type: \"string\"}\n",
        "FC2_USE_LAYNORM='False,False' #@param {type: \"string\"}\n",
        "FC2_ACT='relu,relu' #@param {type: \"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P66oSCBMTtBR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Lastly**, save configs and start training!\n",
        "\n",
        "**PATIENCE**: early stop if dev loss doesn't improve for PATIENCE epochs"
      ]
    },
    {
      "metadata": {
        "id": "TyL09uI3Gd5e",
        "colab_type": "code",
        "outputId": "251fd855-45f7-4b2a-ea5e-a4cabfecdb89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1458
        }
      },
      "cell_type": "code",
      "source": [
        "OPTIMIZER = 'AMSGrad' #@param ['AMSGrad', 'AdamW', 'Adam', 'RMSProp']\n",
        "WEIGHT_DECAY = 0.000 #@param {type:\"number\"}\n",
        "LEARNING_RATE = 1e-5 #@param {type:\"number\"} \n",
        "BATCH_SIZE = 64 #@param {type:\"number\"}\n",
        "MAX_EPOCH = 1500 #@param {type:\"number\"}\n",
        "PATIENCE = 6 #@param {type:\"number\"}\n",
        "WHERE_TO_SAVE = 'Transformer_L4_H16-64batchSize-EF' #@param {type:\"string\"}\n",
        "RANDOM_SEED = 1234 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "# calculate sampling rate (sf), each 150,000 datapoint segment is 37.5 ms\n",
        "down_sample_size = 1\n",
        "if DATASET in ['4000', '4000mid']:\n",
        "  down_sample_size = 4000\n",
        "if DATASET in ['40000', '40000_mid']:\n",
        "  down_sample_size = 40000\n",
        "fs = math.ceil(down_sample_size/0.0375)\n",
        "\n",
        "with open('config_file', 'w') as f:\n",
        "  f.write('[data]\\n')  \n",
        "  f.write('train_src_dir=prepared_data/train_signals\\n')\n",
        "  f.write('train_tgt_dir=prepared_data/train_labels\\n')\n",
        "  f.write('dev_src_dir=prepared_data/dev_signals\\n')\n",
        "  f.write('dev_tgt_dir=prepared_data/dev_labels\\n')\n",
        "  f.write('test_src_dir=prepared_data/test_signals\\n')\n",
        "  f.write('test_tgt_dir=prepared_data/test_labels\\n')\n",
        "  f.write('output_folder=exp/{}/\\n'.format(WHERE_TO_SAVE))\n",
        "  f.write('save_dir=exp/{}/checkpoints/\\n'.format(WHERE_TO_SAVE))\n",
        "  f.write('restore_file=checkpoint_last.pt\\n')\n",
        "  f.write('\\n')\n",
        "  \n",
        "  f.write('[windowing]\\n')\n",
        "  f.write('fs={}\\n'.format(fs))\n",
        "  f.write('\\n')\n",
        "\n",
        "  f.write('[cnn]\\n')\n",
        "  f.write('wlen={}\\n'.format(WLEN))\n",
        "  f.write('cnn_N_filt={}\\n'.format(CNN_N_FILT))\n",
        "  f.write('cnn_len_filt={}\\n'.format(CNN_LEN_FILT))\n",
        "  f.write('cnn_max_pool_len={}\\n'.format(CNN_MAX_POOL_LEN))\n",
        "  f.write('cnn_use_laynorm_inp={}\\n'.format(CNN_USE_LAYNORM_INP))\n",
        "  f.write('cnn_use_batchnorm_inp={}\\n'.format(CNN_USE_BATCHNORM_INP))\n",
        "  f.write('cnn_use_laynorm={}\\n'.format(CNN_USE_LAYNORM))\n",
        "  f.write('cnn_use_batchnorm={}\\n'.format(CNN_USE_BATCHNORM))\n",
        "  f.write('cnn_act={}\\n'.format(CNN_ACT))\n",
        "  f.write('cnn_drop={}\\n'.format(CNN_DROP))\n",
        "  f.write('\\n')\n",
        "  \n",
        "  f.write('[transformer]\\n')\n",
        "  f.write('tr_embed_dim={}\\n'.format(TRANSFORMER_EMBED_DIM))\n",
        "  f.write('tr_max_positions={}\\n'.format(TRANSFORMER_MAX_POSITIONS))\n",
        "  f.write('tr_pos={}\\n'.format(POSITION_EMBEDDING_TYPE))\n",
        "  f.write('tr_num_layers={}\\n'.format(TRANSFORMER_NUM_LAYERS))\n",
        "  f.write('tr_num_heads={}\\n'.format(TRANSFORMER_NUM_HEADS))\n",
        "  f.write('tr_filter_size={}\\n'.format(TRANSFORMER_FILTER_SIZE))\n",
        "  f.write('tr_hidden_size={}\\n'.format(TRANSFORMER_HIDDEN_SIZE))\n",
        "  f.write('tr_dropout={}\\n'.format(TRANSFORMER_DROPOUT))\n",
        "  f.write('tr_attention_dropout={}\\n'.format(TRANSFORMER_ATTENTION_DROPOUT))\n",
        "  f.write('tr_relu_dropout={}\\n'.format(TRANSFORMER_RELU_DROPOUT))\n",
        "  f.write('\\n')\n",
        "  \n",
        "  f.write('[lstm]\\n')\n",
        "  f.write('lstm_embed_dim={}\\n'.format(LSTM_EMBED_DIM))\n",
        "  f.write('lstm_hidden_size={}\\n'.format(LSTM_HIDDEN_SIZE))\n",
        "  f.write('lstm_num_layers={}\\n'.format(LSTM_NUM_LAYERS))\n",
        "  f.write('lstm_bidirectional={}\\n'.format(LSTM_BIDIRECTIONAL))\n",
        "  f.write('lstm_dropout_in={}\\n'.format(LSTM_DROPOUT_IN))\n",
        "  f.write('lstm_dropout_out={}\\n'.format(LSTM_DROPOUT_OUT))\n",
        "  f.write('\\n')\n",
        "  \n",
        "  f.write('[dnn_before]\\n')\n",
        "  f.write('fc1_lay_use={}\\n'.format(FC1_LAY_USE))\n",
        "  f.write('fc1_lay={}\\n'.format(FC1_LAY))\n",
        "  f.write('fc1_drop={}\\n'.format(FC1_DROP))\n",
        "  f.write('fc1_use_laynorm_inp={}\\n'.format(FC1_USE_LAYNORM_INP))\n",
        "  f.write('fc1_use_batchnorm_inp={}\\n'.format(FC1_USE_BATCHNORM_INP))\n",
        "  f.write('fc1_use_batchnorm={}\\n'.format(FC1_USE_BATCHNORM))\n",
        "  f.write('fc1_use_laynorm={}\\n'.format(FC1_USE_LAYNORM))\n",
        "  f.write('fc1_act={}\\n'.format(FC1_ACT))\n",
        "  f.write('\\n')\n",
        "\n",
        "  f.write('[dnn_after]\\n')\n",
        "  f.write('fc2_lay={}\\n'.format(FC2_LAY))\n",
        "  f.write('fc2_drop={}\\n'.format(FC2_DROP))\n",
        "  f.write('fc2_use_laynorm_inp={}\\n'.format(FC2_USE_LAYNORM_INP))\n",
        "  f.write('fc2_use_batchnorm_inp={}\\n'.format(FC2_USE_BATCHNORM_INP))\n",
        "  f.write('fc2_use_batchnorm={}\\n'.format(FC2_USE_BATCHNORM))\n",
        "  f.write('fc2_use_laynorm={}\\n'.format(FC2_USE_LAYNORM))\n",
        "  f.write('fc2_act={}\\n'.format(FC2_ACT))\n",
        "  f.write('\\n')\n",
        "  \n",
        "  f.write('[optimization]\\n')\n",
        "  f.write('optimizer={}\\n'.format(OPTIMIZER))\n",
        "  f.write('weight_decay={}\\n'.format(WEIGHT_DECAY))\n",
        "  f.write('lr={}\\n'.format(LEARNING_RATE))\n",
        "  f.write('batch_size={}\\n'.format(BATCH_SIZE))\n",
        "  f.write('N_epochs={}\\n'.format(MAX_EPOCH))\n",
        "  f.write('seed={}\\n'.format(RANDOM_SEED))\n",
        "  f.write('cuda=True\\n')\n",
        "  f.write('patience={}\\n'.format(PATIENCE))  \n",
        "          \n",
        "!mkdir -p exp/$WHERE_TO_SAVE/\n",
        "!cp config_file exp/$WHERE_TO_SAVE/\n",
        "!python run.py --cfg=config_file --model=$MODEL"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading config file...\n",
            "FunTimes: 1847511 parameters\n",
            "CommandException: Wrong number of arguments for \"cp\" command.\n",
            "CommandException: No URLs matched: gs://edinquake/MLP/exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_last.pt\n",
            "***** Started training at 2019-03-22 09:09:40.433907 *****\n",
            "Epoch 000: loss 5.008 | grad_norm 0.4313 | clip 0\n",
            "Epoch 000: valid_loss 5.24 | valid_perplexity 188\n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_best.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_last.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Epoch 001: loss 5.009 | grad_norm 0.4317 | clip 0\n",
            "Epoch 001: valid_loss 5.24 | valid_perplexity 188\n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_best.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_last.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Epoch 002: loss 5.016 | grad_norm 0.4349 | clip 0\n",
            "Epoch 002: valid_loss 5.23 | valid_perplexity 188\n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_best.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_last.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Epoch 003: loss 5.016 | grad_norm 0.4372 | clip 0\n",
            "Epoch 003: valid_loss 5.23 | valid_perplexity 187\n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_best.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_last.pt [Content-Type=application/octet-stream]...\n",
            "/ [1 files][ 28.2 MiB/ 28.2 MiB]                                                \n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Epoch 004: loss 5.027 | grad_norm 0.4428 | clip 0\n",
            "Epoch 004: valid_loss 5.23 | valid_perplexity 187\n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_best.pt [Content-Type=application/octet-stream]...\n",
            "/ [1 files][ 28.2 MiB/ 28.2 MiB]                                                \n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_last.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Epoch 005: loss 5.001 | grad_norm 0.4489 | clip 0\n",
            "Epoch 005: valid_loss 5.23 | valid_perplexity 187\n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_best.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_last.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Epoch 006: loss 5.002 | grad_norm 0.4586 | clip 0\n",
            "Epoch 006: valid_loss 5.23 | valid_perplexity 186\n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_best.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Copying file://exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_last.pt [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "No validation set improvements observed for 6 epochs. Early stop!\n",
            "Best perplexity is 186.30985796410667\n",
            "Best MAE is 5.227411190668742\n",
            "Copying gs://edinquake/MLP/exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_best.pt...\n",
            "/ [1 files][ 28.2 MiB/ 28.2 MiB]                                                \n",
            "Operation completed over 1 objects/28.2 MiB.                                     \n",
            "Loaded checkpoint exp/Transformer_L4_H16-64batchSize-EF/checkpoints/checkpoint_best.pt\n",
            "Last Epoch 6\n",
            "Best Epoch 0\n",
            "Best MAE Loss 5.227411190668742\n",
            "Best Loss 186.30985796410667\n",
            "***** Finished training at 2019-03-22 09:11:59.475789 *****\n",
            "Evaluate model with Test Set\n",
            "100% 41/41 [00:04<00:00,  9.05it/s]\n",
            "            time_to_failure\n",
            "seg_id                     \n",
            "seg_00030f         0.703751\n",
            "seg_0012b5         0.703767\n",
            "seg_00184e         0.703755\n",
            "seg_003339         0.703756\n",
            "seg_0042cc         0.703731\n",
            "Prediction saved as Transformer_features_submission.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hlHwi3T1g_jj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# import os\n",
        "# import torch\n",
        "# from torch.serialization import default_restore_location\n",
        "# state_dict = {}\n",
        "\n",
        "# # print (os.listdir('.'))\n",
        "# checkpoint_path = os.path.join('./exp/{}/checkpoints'.format(WHERE_TO_SAVE), 'checkpoint_best.pt')\n",
        "# if os.path.isfile(checkpoint_path):\n",
        "#   print('exist')\n",
        "#   state_dict = torch.load(checkpoint_path, map_location=lambda s, l: default_restore_location(s, 'cpu'))\n",
        "  \n",
        "# print (state_dict['best_mae_loss'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGvqQypE3DrC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def load_checkpoint(save_dir, restore_file, model, optimizer):\n",
        "# \t\tcheckpoint_path = os.path.join(save_dir, restore_file)\n",
        "# \t\tsubprocess.call(['gsutil', 'cp', 'gs://edinquake/MLP/{}'.format(checkpoint_path), checkpoint_path])\n",
        "# \t\tif os.path.isfile(checkpoint_path):\n",
        "# \t\t\t\tstate_dict = torch.load(checkpoint_path, map_location=lambda s, l: default_restore_location(s, 'cpu'))\n",
        "# \t\t\t\tmodel.load_state_dict(state_dict['model'])\n",
        "# \t\t\t\toptimizer.load_state_dict(state_dict['optimizer'])\n",
        "# \t\t\t\tsave_checkpoint.best_loss = state_dict['best_loss']\n",
        "# \t\t\t\tsave_checkpoint.last_epoch = state_dict['last_epoch']\n",
        "# \t\t\t\tprint('Loaded checkpoint {}'.format(checkpoint_path))\n",
        "# return state_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UCVomglqNham",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**(Optional)** Download prediction!"
      ]
    },
    {
      "metadata": {
        "id": "MwQYT_OSwEkH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('{}_submission.csv'.format(MODEL))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N1t5apBshAcu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Results (on Kaggle public scoreboard)\n",
        "# SVM, RF & XGB 1.536\n",
        "# LSTM    1.541\n",
        "# SincNet 4000  dim last point 2.736\n",
        "# CNN     40000 dim last point 2.238\n",
        "\n",
        "# ====================================================\n",
        "# Below, all results on dev\n",
        "# ====================================================\n",
        "# |||Using Raw|||\n",
        "\n",
        "# (4000 raw waveform, using last point)\n",
        "# SincNet 2.88\n",
        "# CNN     2.61\n",
        "\n",
        "# (40000 raw waveform, using last point)\n",
        "# SincNet 2.71\n",
        "# CNN     2.57\n",
        "\n",
        "# (4000 raw waveform, using mid point)\n",
        "# SincNet 2.64\n",
        "# CNN     2.49\n",
        "# LSTM    2.751 (4layer biLSTM 128, MLP 10, 10)\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# |||Using features|||\n",
        "# Transformer (last point)\n",
        "# layer  dim      score\n",
        "# 4      256      2.07 AMSGrad / 16 Transformer Heads / Batchnorm / BatchSize 8\n",
        "\n",
        "# ======================================================\n",
        "# |||Using features|||\n",
        "# Transformer (mid point)\n",
        "# layer  dim      score\n",
        "# 2      8        2.3\n",
        "# 2      256      2.26\n",
        "# 4      256      2.24\n",
        "# 4      256      2.19 (Adam)    1.621 on Kaggle\n",
        "# 4      256      2.15 AMSGrad / 16 Transformer Heads / Batchnorm\n",
        "# 5      256      2.59 AMSGrad / 16 Transformer Heads / Batchnorm\n",
        "# 4      256      2.34 AMSGrad / 16 Transformer Heads / Batchnorm / Weight decay 0.0001\n",
        "# 4      256      2.23 AMSGrad / 16 Transformer Heads / Batchnorm / BatchSize 128\n",
        "# 4      256      2.11 AMSGrad / 16 Transformer Heads / Batchnorm / BatchSize 32\n",
        "# 4      256      2.10 AMSGrad / 16 Transformer Heads / Batchnorm / BatchSize 16\n",
        "# 4      256      2.06 AMSGrad / 16 Transformer Heads / Batchnorm / BatchSize 8\n",
        "# 4      256      2.09 AMSGrad / 16 Transformer Heads / Batchnorm / BatchSize 4\n",
        "\n",
        "\n",
        "\n",
        "# LSTM results (mid point)\n",
        "# Same settings (MLP_layer 1, MLP_dim 10)\n",
        "# dir layer  score   LSTM_dim    \n",
        "# bi  1      2.44      48\n",
        "# s   1      2.48\n",
        "# bi  2      2.36\n",
        "# s   2      2.49\n",
        "# bi  4      2.32\n",
        "# bi  8      2.36\n",
        "\n",
        "# bi  4      2.28      128\n",
        "# bi  4      2.26      256\n",
        "\n",
        "\n",
        "\n",
        "# Same settings (bi, 4 lstm layer, lstm_dim 128)\n",
        "# MLP_layer    MLP_dim     score\n",
        "# 1            100         2.31\n",
        "# 1\t\t\t 200\t\t 2.31\n",
        "\n",
        "# 2            10, 10      2.27\n",
        "# 3            10, 10, 10  2.26\n",
        "# 3            100, 10, 10 2.27\n",
        "\n",
        "# LOL WTF AFTER BUG FIX\n",
        "# 3            10, 10, 10  3.11\n",
        "# ===================================================\n",
        "# |||Using more features|||\n",
        "# Same settings (bi, 4 lstm layer, lstm_dim 128)\n",
        "# MLP_layer    MLP_dim     score\n",
        "# 3            10, 10, 10  2.27\n",
        "# 1            10          2.31\n",
        "\n",
        "\n",
        "# Transformer (mid point)\n",
        "# layer  dim      score\n",
        "# 4      256      2.33 AMSGrad \n",
        "# 4      256      2.-- AMSGrad / 16 Transformer Heads / Batchnorm / BatchSize 8 Transformer_L4_H16-8batchSize\n",
        "\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# |||Using Sliding features|||\n",
        "# Transformer (mid point)\n",
        "# layer  dim      score\n",
        "# 4      256      ~2.03 AMSGrad 1.532 on Kaggle 8 Transformer Head, Layernorm\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}